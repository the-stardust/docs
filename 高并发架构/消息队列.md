## 前言

面试官的问你是否使用过消息队列的时候，一般都是连环炮的发问
- 有没有用过消息队列?用过
- 怎么用的?巴拉巴拉
- 为什么用消息队列，直接使用接口调用不行么？...大佬让用的
- 那说一下消息队列的优缺点?。。。异步削峰解耦。。。
- 说下kafka、activeMQ、RabbitMQ、RocketMQ的区别？没用过。。
- 如何保证消息队列的高可用?集群保证 怎么设计集群，原理是什么？。。不知道
- 如果保证消息队列的幂等性，保证消息不被重复消费?不知道。。
- 如何保证消息队列的可靠性传输(消息丢失)
- 如何保证消息的顺序性
- 如何解决消息队列的延时和过期失效问题
- 让你写一个消息队列，有什么架构设计说下思路

一般人是扛不住这么问的，只有你去认真研究了之后，懂得原理之后，才能以不变应万变


## 为什么使用消息队列

直接使用接口调用不好么，加入了消息队列这一层，系统的复杂性又增加了，还要保证消息不丢失，系统稳定性等等问题(消息队列的优缺点)？Kafka、ActiveMQ、RabbitMQ、RocketMQ 都有什么区别，以及适合哪些场景？

这个问题其实面试官是想知道你们有一个什么**业务场景**，这个业务场景有什么技术挑战，如果不用MQ会很麻烦，但是用了之后会有很多好处，接下来就说一下有什么好处，核心就是三个：**异步、削峰、解耦**

### 解耦

A系统需要发送消息到BCD三个系统，使用接口调用的话，再添加一个E系统、或者B系统不再需要接受的话，这样子搞起来，A系统的负责人就直接崩溃了，因为这几个系统产生了严重的耦合，如果A发送给B出现了问题，也会连累到CD系统

所以可以添加一个消息中间件系统，A系统只负责发送给消息中间件，其他的不用管，由消息中间件来和BCD甚至E系统进行对接，这样子A系统就彻底跟其他系统解耦了

**面试技巧**：你需要去考虑一下你负责的系统中是否有类似的场景，就是一个系统或者一个模块，调用了多个系统或者模块，互相之间的调用很复杂，维护起来很麻烦。但是其实这个调用是不需要直接同步调用接口的，如果用 MQ 给它异步化解耦，也是可以的，你就需要去考虑在你的项目里，是不是可以运用这个 MQ 去进行系统的解耦。在简历中体现出来这块东西，用 MQ 作解耦。

### 异步

想象一下这个场景，当A系统发送给B系统需要300ms处理写库和代码逻辑，发送给C系统需要400ms，发送给D系统需要500ms，那么完成这个消息发送的动作，就需要300+400+500=1.2秒，这样子就太慢了，用户等不了

如果使用MQ，A系统发送给消息中间件需要50ms，之后就直接返回用户成功的消息，这样子用户就不会产生系统很慢的印象了


### 削峰

如果每天0:00到12:00 A系统风平浪静，每秒并发请求50个，但是一到12:00-13:00 每秒并发就暴增到5k+，但是系统基于mysql的，大量的请求涌入mysql，会导致mysql出现问题

但是过去高峰期，下午的时候，并发数就又降下来了，对系统也没什么压力了

如果我们使用MQ，每秒5k个请求写进来，而A系统每秒最多处理2k个请求(一般的mysql每秒也就能处理2k个请求)，A系统就每秒从消息中间件里面拉取2k个请求，虽然会有消息挤压，但是哪怕高峰期，系统也不会崩溃，这种短暂的消息挤压是ok的，高峰期一过，A系统就会迅速的把消息中间件里面的消息给消费掉

### 消息队列的优缺点

- 优点就是那三个**异步、削峰、解耦**
- 缺点：
	
    1.系统可用性降低，因为需要额外维护一个消息队列系统，需要保证高可用
    
    2.系统的复杂度提高，要避免消息重复消费，消息丢失
    
    3.一致性问题，A系统发送完消息就以为成功，但是BCD三个系统出现纰漏，数据就不一致了
    
    
### Kafka、ActiveMQ、RabbitMQ、RocketMQ 有什么优缺点？

特性 | ActiveMQ |  RabbitMQ  |  RocketMQ  | Kafka  |
-|-|-|-|-
单机吞吐量| 万级，比 RocketMQ、Kafka 低一个数量级	 | 同 ActiveMQ |10 万级，支撑高吞吐	 |10 万级，高吞吐，一般配合大数据类的系统来进行实时数据计算、日志采集等场景 |
topic 数量对吞吐量的影响	 |  |  |topic 可以达到几百/几千的级别，吞吐量会有较小幅度的下降，这是 RocketMQ 的一大优势，在同等机器下，可以支撑大量的 topic |topic 从几十到几百个时候，吞吐量会大幅度下降，在同等机器下，Kafka 尽量保证 topic 数量不要过多，如果要支撑大规模的 topic，需要增加更多的机器资源|
时效性	| ms级 | 微秒级，这是 RabbitMQ 的一大特点，延迟最低|ms级 |ms级以内 |
可用性	| 高，基于主从架构实现高可用 | 同 ActiveMQ |非常高，分布式架构	|非常高，分布式，一个数据多个副本，少数机器宕机，不会丢失数据，不会导致不可用 |
消息可靠性| 有较低的概率丢失数据 | 基本不丢 |经过参数优化配置，可以做到 0 丢失|同 RocketMQ|
功能支持|MQ 领域的功能极其完备 |基于 erlang 开发，并发能力很强，性能极好，延时很低 |MQ 功能较为完善，还是分布式的，扩展性好|功能较为简单，主要支持简单的 MQ 功能，在大数据领域的实时计算以及日志采集被大规模使用|
    
    
### 建议

一般的业务系统要引入 MQ，最早大家都用 ActiveMQ，但是现在确实大家用的不多了，没经过大规模吞吐量场景的验证，社区也不是很活跃，所以大家还是算了吧，我个人不推荐用这个了；

后来大家开始用 RabbitMQ，但是确实 erlang 语言阻止了大量的 Java 工程师去深入研究和掌控它，对公司而言，几乎处于不可控的状态，但是确实人家是开源的，比较稳定的支持，活跃度也高；

不过现在确实越来越多的公司会去用 RocketMQ，确实很不错，毕竟是阿里出品，但社区可能有突然黄掉的风险（目前 RocketMQ 已捐给 Apache，但 GitHub 上的活跃度其实不算高）对自己公司技术实力有绝对自信的，推荐用 RocketMQ，否则回去老老实实用 RabbitMQ 吧，人家有活跃的开源社区，绝对不会黄。

所以中小型公司，技术实力较为一般，技术挑战不是特别高，用 RabbitMQ 是不错的选择；大型公司，基础架构研发实力较强，用 RocketMQ 是很好的选择。

如果是大数据领域的实时计算、日志采集等场景，用 Kafka 是业内标准的，绝对没问题，社区活跃度很高，绝对不会黄，何况几乎是全世界这个领域的事实性规范。
    
## 如何保证消息队列的高可用

### RabbitMQ

RabbitMQ是基于主从架构(非分布式)来做高可用的

#### 普通集群模式 
   在多台机器启动多个RabbitMQ进程，每台一个进程，你**创建的queue，只会放在一个RabbitMQ实例上**，但是每个实例都会同步queue的元数据(配置信息等，通过元数据可以找到queue所在实例),消费的时候，实际上如果连接到了别的实例上，那么这个实例就会从queue所在的实例上拉取数据过来
    ![upload successful](http://blogs.xinghe.host/images/pasted-144.png)
    
缺点：
- 没做到所谓的分布式，有单实例瓶颈
- 有数据拉取的开销
- 开启持久化后，消息不一定丢失，但是得等这个实例恢复了，然后才可以继续从这个queue拉取数据
- 没有什么所谓的高可用，只是提升了吞吐量

#### 镜像模式集群
  高可用模式，你所创建的queue，无论元数据还是queue的消息，都会**存在于多个实例上**，就是每个RabbitMQ节点都有这个queue的镜完整镜像，每次写消息到queue里面的时候，就会同步给其他的镜像
![upload successful](http://blogs.xinghe.host/images/pasted-146.png)

缺点:
- 没有办法线性扩展，你新增机器，新增的机器上面也有其他queue的信息，如果queue数据量很大，单台机器容量是瓶颈

### kafka
kafka是由多个broker组成，每个broker是一个节点，你创建一个topic，这个topic可以划分为多个partition，每个partition可以存在不同的broker上面，每个partition存放一部分数据(跟es的架构类似)

这就是**天然的分布式消息队列**，每个topic**分散存在于多个机器上，每个机器放一部分数据**

#### HA机制

kafka的高可用分布式架构就是基于HA机制的，也就是replica副本机制，每个partition都有自己的副本，每个replica会选举出来一个leader

那么生成和消费都和这个leader打交道，其他的replica都是follower，写的时候，leader负责把数据同步给其他的follower，读的时候，就直接读leader上的数据，(**要是你想随意读写每个follower，就要care数据一致性问题**)，

kafka会均匀的把一个partition的所有replica分布在不同的机器上，这样才可以提高容错性
![upload successful](http://blogs.xinghe.host/images/pasted-147.png)

这样子就实现了**高可用**了，如果某个broker宕机，那这个broker上面的partition再其他机器上都有副本，如果宕机的broker上面有某个partition的leader，那么follower会**重新选举**出来一个leader

**写数据时**，生产者就写leader，然后leader将数据落地到磁盘，接着其他的follower自己主动从leader上面pull数据，一旦所有的follower同不好数据了，就会发生ack给leader，leader返回给生产者(这只是其中一种模式)

**消费**的时候，只会从 leader 去读，**但是只有当一个消息已经被所有 follower 都同步成功返回 ack 的时候**，这个消息才会被消费者读到。

## 如何保证消息不被重复消费

!> 如何保证消息的幂等性

kafka有一个offset的概念，类似每个消息都有一个序号，消费者每隔一段时间都会返回给kafka这个offset，证明我已经消费到了该offset，当我断电或者重启的时候，你就从当前offset给我后续的消息

此时如果kafka还没来得及提交offset，就断点了，重启后，就会重复消费消息

通常保证幂等性还需要业务系统来维持，此处提供几个思路

- 写数据库的话，就指定一个唯一键，写入的时候查询一下，存在就不写入了
- 写redis的话，每次set都没问题，redis是天然幂等性
- 生产者每次生成一个唯一id，消费者消费前先在redis或者数据库中查询一个这个id是否存在

**当然，如何保证 MQ 的消费是幂等性的，需要结合具体的业务来看。**

## 如何保证消息可靠性传输

![upload successful](http://blogs.xinghe.host/images/pasted-148.png)

### 生产者丢失消息

RabbitMQ 有两种机制，一个是事物机制，一个是confirm机制，**事物机制会同步的，会阻塞，降低吞吐量，消耗性能，confirm是异步的**

kafka有个情况，某个broker宕机，然后partition重选leader，但是，当此时其他follower还有部分数据没有同步，此时leader挂了，然后重新选出leader，那么没同步的数据就丢失了

为了解决这种情况，可以设置以下参数：

- 给 topic 设置 replication.factor 参数：这个值必须大于 1，要求每个 partition 必须有至少 2 个副本。
- 给 kafka 服务端设置min.insync.replicas,这个值必须大于1，标识要求一个leader至少感知到至少一个follower还跟自己保持联系，没掉队，这样才能确保leader挂了还有一个follower
- 给producer端设置，acks=all，这个是要求每条数据，必须**写入全部replica之后，才认为写入成功**
- 给producer端社会acks=MAX(很大很大的一个值),这是**要求一旦写入失败，就无限重试**

### 消息中间件丢失消息

#### RabbitMQ
可以设置持久化，就算是断点了，消息也会持久化到磁盘，恢复后可以读取之前存储到磁盘的信息，**除非RabbitMQ 还没持久化，自己就挂了，可能导致少量数据丢失，但是这个概率较小。**

开启持久化
- 创建queue的时候设置持久化，queue持久化
- 发送消息的时候将消息的deliveryMode设置为2，表示消息持久化

必须两个都开启，还有一种可能是，接收到消息后，还没持久化就断电了，这样子内存中的消息会丢失一点，解决办法是和confirm机制联合起来，当持久化完毕之后，再回应ack

#### kafka

按照上面的设置后，kafka就不会丢消息了

### 消费端丢失消息

#### RabbitMQ

RabbitMQ 如果丢失了数据，主要是因为你消费的时候，刚消费到，还没处理，结果进程挂了，比如重启了，那么就尴尬了，RabbitMQ 认为你都消费了，这数据就丢了。

这种解决方案是，关闭自动的ack机制，当消费完之后，用程序去回应ack，这样子消息就不会丢了

#### kafka

kafka自动提交offset，解决方案也是类似，关闭自动提交offset，程序消费完消息后手动提交offset

但是还会有一种情况就是，消费完消息后，没来得及提交offset，程序挂了，这时候就会重复消费，解决方案就是结合自己的业务，保证消息的幂等性就行了

## 如何保证消息的顺序性

当消费者是多线程的时候，消息的顺序就不能够被保证，这样子就会出问题

### 解决方案

#### RabbitMQ

拆分多个queue，每个queue一个consumer，然后每个consumer内部用内存队列做排队，然后分发给底层不同的worker来处理

![upload successful](http://blogs.xinghe.host/images/pasted-149.png)

这样子好像吞吐量就会降低了。。。。

#### kafka

- 一个topic一个partition，一个consumer，内部单线程消费，但是吞吐量太低，一般不用这个
- 写N个内存queue，具有相同key的消息扔到同一个queue里面，然后对应N个线程，每个线程消费一个queue即可
![upload successful](http://blogs.xinghe.host/images/pasted-150.png)

## 如何保证消息的过期失效和延时

一般出现这种问题就是消费端出现了问题，或者是消费的速度与生产的速度差一个数量级，当你消息都快写満磁盘了，都没人消费，这样子消息就会溢出，丢失一些消息，或者消息都过期失效了

### 大量消息在MQ里积压几小时还没解决

一般会紧急扩容
- 先修复消费端的问题，把bug解决了，然后将所有的consumer停掉
- 新建一个topic，partition是原来的10倍，临时建立好原来10倍的queue
- 然后写一个临时分发消息到consumer的程序，这个程序部署上去消费积压的数据，**消费之后不做耗时的处理**，直接均匀轮询的写入到临时建好的10倍的queue
- 接着征用10倍的机器来部署consumer，每一批consumer消费一个临时的queue的数据，这种做法相当于临时将queue资源和consumer资源扩大了10倍，以正常10倍的速度消费数据
- 等快熟消费完积压的数据后，**恢复原来的架构，重新**用原来的consumer机器来消费

### MQ里面的消息过期失效了

这个也是由于queue里面的消息积压了许久，消息都过期丢失了，被消息中间件给清除了，这个是**大量的数据直接丢失了**

这个情况可以采用**批量重导**，过了高峰期的时候，比如夜里12点，开始写程序，将丢失的诗句，写个临时程序，一点一点的查出来，然后倒入mq中去，给补回来，只能这样了


### MQ快满了

这个也只能写程序来处理挤压的消息了，跟上面一样，等晚上再补数据

## 如何设计一个消息队列

其实聊到这个问题，一般面试官要考察两块：

- 你有没有对某一个消息队列做过较为深入的原理的了解，或者从整体了解把握住一个消息队列的架构原理。
- 看看你的设计能力，给你一个常见的系统，就是消息队列系统，看看你能不能从全局把握一下整体架构设计，给出一些关键点出来。

考虑的角度应该有
- 首先这个mq应该支持可伸缩性，需要的时候可以快速扩容，增加吞吐量，这样子就要设计一个分布式系统，参照kafka的概念，分片、多副本，多机器部署
- 其实考虑mq的持久化，因为内存在断电后就丢失消息了，所以得保证能持久化消息，怎么落盘性能高啊，参照kafka，顺序写，这样磁盘就没有随机读写的寻址开销了，
- 还有要考虑mq的可用性，参照kafka，多副本，leader->follower选举机制
- 消息丢失的处理，前面说的confirm机制，ack机制等